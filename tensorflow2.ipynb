{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netword Ready!\n"
     ]
    }
   ],
   "source": [
    "#初始化神经网络参数\n",
    "#第一层节点数\n",
    "n_hidden_1 = 256\n",
    "#第二层节点数\n",
    "n_hidden_2 = 128\n",
    "#输入层\n",
    "n_input = 784\n",
    "#输出层\n",
    "n_classes = 10\n",
    "\n",
    "x = tf.placeholder(\"float\",[None,n_input])\n",
    "y = tf.placeholder(\"float\",[None,n_classes])\n",
    "#初始化，高斯分布，stddev标准差\n",
    "stddev = 0.1\n",
    "weights = {\n",
    "    'w1':tf.Variable(tf.random_normal([n_input,n_hidden_1],stddev=stddev)),\n",
    "    'w2':tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2],stddev=stddev)),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2,n_classes],stddev=stddev))\n",
    "}\n",
    "biases = {\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "print(\"Netword Ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(_X,_weights,_biases):\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(_X,_weights['w1']),_biases['b1']))\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1,_weights['w2']),_biases['b2']))\n",
    "#     return (tf.matmul(layer_2,_weights['out']) + _biases['out'])\n",
    "    return tf.add(tf.matmul(layer_2,_weights['out']),_biases['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTIONS READY\n"
     ]
    }
   ],
   "source": [
    "#预测\n",
    "pred = multilayer_perceptron(x,weights,biases)\n",
    "#loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
    "optm = tf.train.GradientDescentOptimizer(learning_rate = 0.001).minimize(cost)\n",
    "corr = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "accr = tf.reduce_mean(tf.cast(corr,\"float\"))\n",
    "\n",
    "print(\"FUNCTIONS READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/020 cost: 2.383366595\n",
      "TRAIN ACCURACY：0.130\n",
      "Test ACCURACY: 0.132\n",
      "Epoch: 004/020 cost: 2.240368398\n",
      "TRAIN ACCURACY：0.350\n",
      "Test ACCURACY: 0.297\n",
      "Epoch: 008/020 cost: 2.200521219\n",
      "TRAIN ACCURACY：0.400\n",
      "Test ACCURACY: 0.422\n",
      "Epoch: 012/020 cost: 2.154432045\n",
      "TRAIN ACCURACY：0.460\n",
      "Test ACCURACY: 0.478\n",
      "Epoch: 016/020 cost: 2.099822612\n",
      "TRAIN ACCURACY：0.490\n",
      "Test ACCURACY: 0.536\n",
      "Finsh!\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "display_step = 4\n",
    "#launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optm,feed_dict={x:batch_xs,y:batch_ys})\n",
    "        avg_cost += sess.run(cost,feed_dict={x:batch_xs,y:batch_ys})\n",
    "    avg_cost = avg_cost/total_batch\n",
    "    \n",
    "    if epoch % display_step == 0 :\n",
    "        print(\"Epoch: %03d/%03d cost: %.9f\"%(epoch,training_epochs,avg_cost))\n",
    "        train_acc = sess.run(accr,feed_dict={x:batch_xs,y:batch_ys})\n",
    "        print(\"TRAIN ACCURACY：%.3f\"%(train_acc))\n",
    "        train_acc = sess.run(accr,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Test ACCURACY: %.3f\"%(train_acc))\n",
    "print(\"Finsh!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN(卷积神经网络)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#输入节点\n",
    "n_input = 784\n",
    "#输出节点数\n",
    "n_outout = 10\n",
    "#权重\n",
    "weights = {\n",
    "    #卷积层权重\n",
    "    'wc1':tf.Variable(tf.random_normal([3,3,1,64],stddev=0.1)),\n",
    "    #卷积层权重\n",
    "    'wc2':tf.Variable(tf.random_normal([3,3,64,128],stddev=0.1)),\n",
    "    #全连接层权重\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*128,1024],stddev=0.1)),\n",
    "    #输出层权重\n",
    "    'wd2':tf.Variable(tf.random_normal([1024,n_outout],stddev=0.1))\n",
    "}\n",
    "biases = {\n",
    "    'bc1':tf.Variable(tf.random_normal([64],stddev=0.1)),\n",
    "    'bc2':tf.Variable(tf.random_normal([128],stddev=0.1)),\n",
    "    'bd1':tf.Variable(tf.random_normal([1024],stddev=0.1)),\n",
    "    'bd2':tf.Variable(tf.random_normal([n_outout],stddev=0.1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_basic(_input,_w,_b,_keepratio):\n",
    "    #输入层\n",
    "    _input_r = tf.reshape(_input,shape=[-1,28,28,1])\n",
    "    #卷积层1\n",
    "    _conv1 = tf.nn.conv2d(_input_r,_w['wc1'],strides=[1,1,1,1],padding=\"SAME\")\n",
    "    #激活函数\n",
    "    _conv1 = tf.nn.relu(tf.nn.bias_add(_conv1,_b['bc1']))\n",
    "    #池化层\n",
    "    _pool1 = tf.nn.max_pool(_conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "    #随机失活\n",
    "    _pool_drl = tf.nn.dropout(_pool1,_keepratio)\n",
    "    #conv layer2\n",
    "    _conv2 = tf.nn.conv2d(_pool_drl,_w['wc2'],strides=[1,1,1,1],padding=\"SAME\")\n",
    "    #激活函数\n",
    "    _conv2 = tf.nn.relu(tf.nn.bias_add(_conv2,_b['bc2']))\n",
    "    #池化层\n",
    "    _pool2 = tf.nn.max_pool(_conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "    #随机失活\n",
    "    _pool_dr2 = tf.nn.dropout(_pool2,_keepratio)\n",
    "    \n",
    "    #全连接层\n",
    "    _densel = tf.reshape(_pool_dr2,[-1,_w['wd1'].get_shape().as_list()[0]])\n",
    "    #激活函数\n",
    "    _fcl = tf.nn.relu(tf.add(tf.matmul(_densel,_w['wd1']),_b['bd1']))\n",
    "    #随机失活\n",
    "    _fc_dr1 = tf.nn.dropout(_fcl,_keepratio)\n",
    "    _out = tf.add(tf.matmul(_fc_dr1,_w['wd2']),_b['bd2'])\n",
    "    \n",
    "    out = {\n",
    "        'input_r':_input_r,'conv1':_conv1,'pool1':_pool1,\n",
    "        'pool_dr1':_pool_drl,'conv2':_conv2,'pool2':_pool2,\n",
    "        'pool_dr2':_pool_dr2,'dense1':_densel,'fc1':_fcl,\n",
    "        'fc_dr1':_fc_dr1,'out':_out\n",
    "    }\n",
    "    \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y= tf.placeholder(tf.float32,[None,10])\n",
    "keepratio = tf.placeholder(tf.float32)\n",
    "\n",
    "_pred = conv_basic(x,weights,biases,keepratio)['out']\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=_pred,labels=y))\n",
    "optm = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "_corr = tf.equal(tf.argmax(_pred,1),tf.argmax(y,1))\n",
    "accr = tf.reduce_mean(tf.cast(_corr,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/020 cost: 183.615068436\n",
      "Training accuracy: 0.220\n",
      "Epoch: 001/020 cost: 57.183549404\n",
      "Training accuracy: 0.520\n",
      "Epoch: 002/020 cost: 28.334005356\n",
      "Training accuracy: 0.660\n",
      "Epoch: 003/020 cost: 19.346994281\n",
      "Training accuracy: 0.640\n",
      "Epoch: 004/020 cost: 15.639134824\n",
      "Training accuracy: 0.680\n",
      "Epoch: 005/020 cost: 13.976569653\n",
      "Training accuracy: 0.720\n",
      "Epoch: 006/020 cost: 13.146050096\n",
      "Training accuracy: 0.840\n",
      "Epoch: 007/020 cost: 11.411254466\n",
      "Training accuracy: 0.880\n",
      "Epoch: 008/020 cost: 10.884806156\n",
      "Training accuracy: 0.880\n",
      "Epoch: 009/020 cost: 10.261336207\n",
      "Training accuracy: 0.920\n",
      "Epoch: 010/020 cost: 9.416776359\n",
      "Training accuracy: 0.920\n",
      "Epoch: 011/020 cost: 8.749617279\n",
      "Training accuracy: 0.840\n",
      "Epoch: 012/020 cost: 6.961127371\n",
      "Training accuracy: 0.940\n",
      "Epoch: 013/020 cost: 7.402644455\n",
      "Training accuracy: 0.880\n",
      "Epoch: 014/020 cost: 7.346008480\n",
      "Training accuracy: 0.880\n",
      "Epoch: 015/020 cost: 5.873536199\n",
      "Training accuracy: 0.980\n",
      "Epoch: 016/020 cost: 7.291177958\n",
      "Training accuracy: 0.940\n",
      "Epoch: 017/020 cost: 5.037346199\n",
      "Training accuracy: 0.960\n",
      "Epoch: 018/020 cost: 6.880421788\n",
      "Training accuracy: 0.880\n",
      "Epoch: 019/020 cost: 5.189743668\n",
      "Training accuracy: 0.920\n",
      "Finsh!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "trian_epochs = 20\n",
    "batch_size = 50\n",
    "display_step = 1\n",
    "for epoch in range(trian_epochs):\n",
    "    avg_cost = 0\n",
    "#     total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    total_batch = 10\n",
    "    for i in range(total_batch):\n",
    "        batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optm,feed_dict={x:batch_xs,y:batch_ys,keepratio:0.6})\n",
    "        avg_cost += sess.run(cost,feed_dict={x:batch_xs,y:batch_ys,keepratio:0.6})\n",
    "        \n",
    "    if epoch % display_step ==0:\n",
    "        print(\"Epoch: %03d/%03d cost: %.9f\"%(epoch,trian_epochs,avg_cost))\n",
    "        train_acc = sess.run(accr,feed_dict={x:batch_xs,y:batch_ys,keepratio:1.})\n",
    "        print(\"Training accuracy: %.3f\"%(train_acc))   \n",
    "print(\"Finsh!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
